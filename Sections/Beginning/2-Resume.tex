Le réchauffement climatique est l'un des plus grands défis de l'humanité. Les combustibles fossiles sont l'une des principales sources de production d'énergie dans le monde, ce qui entraîne des émissions de gaz à effet de serre (GES) dans l'atmosphère. Ces gaz créent une barrière dans l'atmosphère (comme dans une serre), empêchant la chaleur de se dissiper dans l'espace. Par conséquent, la température de la Terre augmente, en déséquilibrant notre environnement. Le 12 décembre 2015, la Conférence des Nations Unies sur le changement climatique (COP21) a fixé des objectifs pour la fin du 21e siècle. L'objectif principal est de limiter la température à 2 \degree C tout en poursuivant les mesures pour la limiter à 1,5 \degree C. Cependant, des rapports récents montrent que nous nous dirigeons vers une augmentation de la température de 2,8 \degree C. Les températures élevées entraînent plusieurs problèmes, tels que des vagues de chaleur, des sécheresses et des inondations. Ces facteurs ont des impacts directs sur la flore et la faune, augmentent l'insécurité alimentaire et hydrique, ainsi que la mortalité, réduisent la productivité du travail et l'apprentissage, en plus d'augmenter les risques de grossesses à issue défavorables, favoriser les conflits, les discours de haine, les migrations et la propagation des maladies infectieuses.

Les secteurs industriels et académiques sont tous en train de repenser leurs processus et de proposer des solutions au problème du réchauffement de la planète. Le secteur des technologies de l'information et de la communication, qui englobe notamment les centres de données, les ordinateurs et les réseaux, est un important émetteur de GES. Les centres de données sont à eux seuls responsables de 1\% des émissions mondiales de GES liées à l'énergie. Par exemple, en 2015, les centres de données de Google ont dépensé la même quantité d'énergie que l'ensemble de la ville de San Francisco. Un moyen de réduire l'impact des centres de données sur les émissions de GES est de réduire l'énergie nécessaire aux serveurs. Toutefois, certains auteurs ont signalé une réduction des améliorations apportées aux technologies des processeurs. De plus, avec l'augmentation prévue du nombre d'internautes (jusqu'à 5,3 en 2023), la situation tend à s'aggraver. 

Une solution possible consiste à faire passer la production d'énergie (combustibles fossiles) aux sources vertes (sources d'énergie renouvelables - SER). Celles-ci génèrent de l'énergie à partir de sources naturelles, telles que l'énergie solaire, éolienne, géothermique, hydroélectrique, houlomotrice et marémotrice, ainsi que la biomasse. Le terme « renouvelable » découle de l'idée que ces sources se renouvellent constamment. Le plus grand inconvénient de la mise en œuvre des SER est leur intermittence, puisque leur production provient de la nature et dépend des conditions climatiques. Malgré cela, les grands fournisseurs d'informatique en nuage, tels que Google, Amazon et Facebook, investissent dans des centrales solaires et éoliennes. Ils ont mis en place une approche hors site, qui consiste à fournir de l'énergie renouvelable au réseau dans la même proportion qu'ils en consomment. De cette manière, le problème de l'intermittence est transféré à des tiers. 

La création d'un centre de données uniquement renouvelable avec une production renouvelable sur site réduirait considérablement les émissions de gaz à effet de serre des centres de données. C'est ce que propose Datazero2. Néanmoins, un centre de données uniquement renouvelable introduit plusieurs défis dans les domaines de l'énergie et des technologies de l'information. En ce qui concerne l'alimentation électrique, un gestionnaire doit décider de l'utilisation du stockage d'énergie en fonction de la production renouvelable estimée et réelle. D'autre part, la partie informatique doit prendre en charge la production d'énergie et exécuter les tâches de l'utilisateur. Le problème peut être divisé en deux parties : hors ligne et en ligne. La partie hors ligne utilise les prévisions pour planifier les décisions à court terme, tout en prenant en compte le long terme. Par exemple, la partie hors ligne peut estimer une sous-production d'énergie et utiliser plus d'énergie provenant du stockage à court terme, tout en prévoyant de recharger le stockage sous peu. Quant à la partie en ligne, le manager doit appliquer le plan hors ligne, en réagissant aux événements réels du centre de données. Comme les prévisions sont imparfaites, le manager en ligne doit trouver des moyens d'adapter le plan hors ligne, en réduisant l'impact sur les emplois des utilisateurs. En considérant ces éléments, cette thèse propose quelques approches pour combiner les décisions hors ligne et en ligne, en traitant l'incertitude provenant de la production renouvelable et de la demande de la charge de travail.

Tout d'abord, nous proposons quatre politiques de compensation énergétique. L'objectif principal de ces politiques est d'adapter le plan hors ligne pour rapprocher les niveaux de stockage des niveaux prévus à la fin d'une fenêtre temporelle. Ces adaptations sont nécessaires car la production et la demande d'électricité peuvent varier. Par exemple, une surproduction d'énergie renouvelable produirait plus d'énergie que prévu. Le système en ligne peut donc utiliser cette énergie pour exécuter davantage de tâches. D'autre part, il doit réduire l'utilisation dans un scénario de sous-production. Il est essentiel de rapprocher les niveaux de stockage des niveaux prévus, car le stockage de l'énergie est limité. De plus, le centre de données fonctionne sans interruption. Il n'est donc pas viable de toujours utiliser plus de batterie que prévu pour chaque fenêtre temporelle. Nous démontrons l'impact du respect des niveaux de stockage sur la qualité de service. 

Ensuite, nous introduisons des algorithmes d'apprentissage par renforcement dans le problème de la compensation, en essayant d'améliorer la qualité de service de nos politiques. Plus précisément, nous utilisons ces algorithmes pour définir comment compenser les différents scénarios, dans le but d'augmenter le nombre de travaux terminés. Ainsi, nous pourrions toujours respecter les niveaux de stockage d'énergie tout en améliorant la qualité de service.

Enfin, notre dernière contribution est une heuristique qui combine les décisions relatives à la puissance et à l'ordonnancement, dans le but de réduire le nombre de tâches abandonnées et le gaspillage d'énergie. Cette heuristique s'appelle BEASY et utilise les prédictions pour prendre de meilleures décisions, en trouvant les moments dangereux pour être plus prudent. BEASY respecte les contraintes de puissance, avec un faible gaspillage d'énergie et le plus faible nombre de tâches détruites parmi tous les algorithmes.