Global warming is one of the biggest humanity challenges. Fossil fuels are one of the world's main sources of energy production, which emits greenhouse gas emissions (GHG) in the atmosphere. This gas creates a barrier in the atmosphere, not allowing heat dissipation in the space. Therefore, Earth's temperature increases, unbalancing our environment. Paris Agreement established some objectives for the end of Century 21. The main goal is to limit the temperature increase to 2 \degree C, trying to limit it to 1.5 \degree C. However, recent reports show we are walking toward a temperature increase of 2.8 \degree C. High temperatures lead to climate and health problems. Different sectors are rethinking their processes and proposing solutions to the global warming problem. The data center sector is a significant GHG emitter, with 1\% of the global energy-related GHG emissions. A way to reduce the data center's impact on GHG emissions is by reducing the energy needed by the servers. However, some authors pointed out a reduction in the processor energy improvements. Furthermore, with the expected increase in Internet users (up to 5.3 billion in 2023), the situation tends to get even worse. 

A possible solution is migrating energy production from brown sources (fossil fuels) to green sources (renewable energy sources - RES). It generates energy from natural sources, such as solar and wind. The biggest drawback of implementing RES is its intermittence since its production comes from nature, depending on the climate conditions. Big cloud providers invest in off-site solar and wind power plants, which means they provide renewable energy to the grid with the same amount they expend. Therefore, they transfer the intermittence problem to third parties. The Datazero2 project proposes a renewable-only data center with only on-site renewable production. This kind of data center would drastically reduce their GHG emissions. However, a renewable-only data center introduces several challenges. We deal with these challenges in two parts: offline and online. The offline side uses predictions to plan short-term decisions but considers the long-term. The online side must apply the offline plan, reacting to the actual events of the data center. Since the predictions are imperfect, the online must find ways to adapt the offline plan, reducing the impact on the user's jobs. Considering these elements, this thesis proposes some approaches to mix offline and online decisions, dealing with the uncertainty coming from renewable production and workload demand.

First, we propose four policies for energy compensation. The main objective of these policies is to adapt the offline plan to approximate the storage levels to the planned levels at the end of a time window. These adaptations are necessary since power production and demand can vary. We demonstrate the impact of respecting the storage levels on the Quality of Service (QoS). After that, we introduce Reinforcement Learning algorithms in the compensation problem, trying to improve the QoS of our policies. More specifically, we use these algorithms to define how to compensate for different scenarios, aiming to increase the number of finished jobs. Therefore, we could still respect the energy storage levels and improve the QoS. Finally, our last contribution is a heuristic that mixes both power and scheduling decisions, seeking to reduce the number of killed jobs and wasted energy. This heuristic is named \emph{\systemName} and uses predictions to make better decisions, maintaining the battery between safe thresholds, which increases the battery's lifetime. \emph{\systemName} respects the power constraints, having low wasted energy, and the lower number of killed jobs among all algorithms.