Global warming is one of the biggest humanity challenges. Fossil fuels are one of the world's main sources of energy production, which emits greenhouse gas emissions (GHG) in the atmosphere. This gas creates a barrier in the atmosphere (like in a greenhouse), not allowing heat dissipation in the space. Therefore, Earth's temperature increases, unbalancing our environment. On 12 December 2015, the United Nations Climate Change Conference (COP21) established some objectives for the end of Century 21. The main goal is to limit the temperature to 2 \degree C while pursuing measures to limit it to 1.5 \degree C. However, recent reports show we are walking toward a temperature increase of 2.8 \degree C. High temperatures lead to several problems, such as heatwaves, droughts, and floods, impacting flora and fauna directly, increasing food and water insecurity, increasing mortality, impacting labor productivity, impairing learning, increasing adverse pregnancy outcomes possibility, increasing conflict, hate speech, migration, and infectious disease spread.

All industry and academic sectors are rethinking their processes and proposing solutions to the global warming problem. A significant GHG emitter is the Information and Communications Technology (ICT) sector, which englobes, for example, data centers, computers, and networks. Data centers alone are responsible for 1\% of the global energy-related GHG emissions. For example, Google data centers expended the same amount of energy as the entire city of San Francisco in 2015. A way to reduce the data center's impact on GHG emissions is by reducing the energy needed by the servers. However, some authors pointed out a reduction in the processor technologies improvements. Furthermore, with the expected increase in Internet users (up to 5.3 in 2023), the situation tends to get even worse. 

A possible solution is migrating energy production from brown sources (fossil fuels) to green sources (renewable energy sources - RES). It generates energy from natural sources, such as solar, wind, geothermal, hydropower, wave and tidal, and biomass. The renewable term comes from the idea that these sources are constantly replenished. The biggest drawback of implementing RES is its intermittence since its production comes from nature, depending on the climate conditions. Even so, big cloud providers, such as Google, Amazon, and Facebook, invest in solar and wind power plants. They implemented the off-site approach, which means they provide renewable energy to the grid with the same amount they expend. Therefore, they transfer the intermittence problem to third parties. 

Creating a renewable-only data center with only on-site renewable production would drastically reduce the GHG emissions by the data centers. This is what Datazero2 proposes. However, a renewable-only data center introduces several challenges in both power and IT parts. On the power side, a manager must decide the energy storage usage according to the estimated and real renewable production. On the other hand, the IT side must take the power production and execute the user's jobs. It is possible to divide the problem into two parts: offline and online. The offline side uses predictions to plan short-term decisions but considers the long-term. For example, the offline can estimate a power underproduction and use more energy from storage in the short-term but planning to recharge the storage shortly. On the online side, the manager must apply the offline plan, reacting to the actual events of the data center. Since the predictions are imperfect, the online must find ways to adapt the offline plan, reducing the impact on the user's jobs. Considering these elements, this thesis proposes some approaches to mix offline and online decisions, dealing with the uncertainty coming from renewable production and workload demand.

First, we propose four policies for energy compensation. The main objective of these policies is to adapt the offline plan to approximate the storage levels to the planned levels at the end of a time window. These adaptations are necessary since power production and demand can vary. For example, a renewable overproduction would produce more energy than predicted. So, the online can use this energy to run more jobs. On the other hand, it must reduce the usage in an underproduction scenario. Approximating the storage levels to the planned levels is crucial because energy storage is limited. Also, the data center runs uninterruptedly. So, it is not viable to always use more battery than expected for every time window. We demonstrate the impact of respecting the storage levels on the Quality of Service. 

After that, we introduce Reinforcement Learning algorithms in the compensation problem, trying to improve the Quality of Service of our policies. More specifically, we use these algorithms to define how to compensate for different scenarios, aiming to increase the number of finished jobs. Therefore, we could still respect the energy storage levels but also improve the Quality of Service. 

Finally, our last contribution is a heuristic that mixes both power and scheduling decisions, seeking to reduce the number of killed jobs and wasted energy. This heuristic is named \emph{\systemName} and uses predictions to make better decisions, finding dangerous moments to be more cautious. \emph{\systemName} respects the power constraints, having low wasted energy, and the lower number of killed jobs among all algorithms.